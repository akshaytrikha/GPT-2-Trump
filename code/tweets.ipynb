{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data from yearly files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2605 tweets from 2017\n",
      "4225 tweets from 2016\n",
      "7536 tweets from 2015\n",
      "3510 tweets from 2018\n",
      "17876\n"
     ]
    }
   ],
   "source": [
    "# get all files in data directory\n",
    "# data sourced from https://github.com/bpb27/trump_tweet_data_archive\n",
    "all_files = list(os.walk(\"./data/\"))\n",
    "\n",
    "# list containing extracted data\n",
    "data = []\n",
    "\n",
    "# loop through files and combine all tweets in a list of dictionaries\n",
    "for item in all_files:\n",
    "    foldername, dirs, files = item\n",
    "    for file in files:\n",
    "        # if filetype is .json\n",
    "        if \".json\" in file:\n",
    "            with open(\"./data/\" + file) as open_file:\n",
    "                # read data from json file as str\n",
    "                lines  = open_file.read()\n",
    "                # now list of dictionaries (each tweet is a dict)\n",
    "                file_data = json.loads(lines)\n",
    "                print(len(file_data), \"tweets from\", file[-9:-5])\n",
    "                data += file_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate each tweet with <|endoftext|> delimeter in output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/tweets.txt\", \"w+\") as out_file:\n",
    "    # loop through tweets\n",
    "    for i in range(len(data)):\n",
    "        # must not be a retweet\n",
    "        if data[i][\"is_retweet\"] == False :\n",
    "            tweet = data[i][\"text\"]\n",
    "            # if tweet includes a hyperlink\n",
    "            https_index = tweet.find(\"https://\")\n",
    "            if https_index != -1:\n",
    "                # clean tweet of hyperlink\n",
    "                tweet = tweet[:https_index]\n",
    "\n",
    "            # write tweet to file followed by delimiter\n",
    "            out_file.write(tweet + \"\\n\\n\" + \"<|endoftext|>\" + \"\\n\\n\")\n",
    "        \n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, it was my great honor to sign a new Executive Order to ensure Veterans have the resources they need as they transition back to civilian life. We must ensure that our HEROES are given the care and support they so richly deserve! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
